[news]
max_articles = 5
# This system prompt is now used internally by the NewsAggregator
system_prompt = """You are a news article analyzer that reviews scraped content."""
# News sites to scrape for Hudson, Ohio news
news_sites = [
  "https://hudsonohiotoday.com/",
  "https://www.beaconjournal.com/communities/hudsonhubtimes/",
  "https://fox8.com/tag/hudson-news/",
  "https://thesummiteer.org/posts",
  "https://www.news5cleveland.com/news/local-news/oh-summit/",
  "https://www.wkyc.com/section/summit-county",
]
# Skip URLs that were scraped within this many hours (default 24)
scraping_cache_hours = 2160  # 90 days
# Whether to skip recently scraped URLs (default true)
skip_recently_scraped = true

[reddit]
subreddit = "hudsonoh"
user_agent = "hudson-news-bot/0.1.0"
check_for_duplicates = true
max_search_results = 100

[claude]
max_turns = 10
permission_mode = "readOnly"
timeout_seconds = 300

[database]
path = "data/submissions.db"
